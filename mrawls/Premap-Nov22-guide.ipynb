{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A guide for Nov 22\n",
    "Goal: plot an LSST light curve as well as a HiTS light curve, then explore some more on your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "import tarfile\n",
    "import sqlite3\n",
    "import lsst.daf.persistence as dafPersist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should all be familiar from last time\n",
    "hitsDataDir = '/epyc/users/mrawls/premap2019/hits-dr1'\n",
    "hitsFilename = 'HiTS_DR1_variables_DM-dataset-subset.fits'\n",
    "hitsFilepath = os.path.join(hitsDataDir, hitsFilename)\n",
    "hitsTable = fits.open(hitsFilepath)  # load data as an astropy fits thing\n",
    "hitsDf = pd.DataFrame(hitsTable[1].data)  # turn data into a pandas dataframe\n",
    "hitsDf.head()  # show us (print out) what the dataframe looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hits(row, lcPath='/epyc/users/mrawls/premap2019/hits-dr1/light_curves'):\n",
    "    '''Plots light curves from HiTS DR1.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    row : Pandas Dataframe row from DR1 source data\n",
    "    lcPath : Path on disk to light curves from DR1\n",
    "    '''\n",
    "    tok = row['internalID'].split('_')\n",
    "    field = '_'.join([tok[0], tok[1]])\n",
    "    ccd = tok[2]\n",
    "    lightcurveFile = field + '_' + ccd + '_LC_50.tar.gz'\n",
    "    tarball = tarfile.open(os.path.join(lcPath, field, ccd, lightcurveFile))\n",
    "    data = tarball.extractfile(row['internalID'] + '_g.dat')\n",
    "    dfl = pd.read_csv(data, sep='\\t')  # load a file with light curve data into a pandas dataframe\n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    plt.errorbar(dfl.MJD, dfl.MAG_AP1, dfl.MAGERR_AP1, marker='o', linestyle=':')\n",
    "    plt.xlabel('Time (MJD)')\n",
    "    plt.ylabel('magnitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That was fun, now let's do LSST things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = '/epyc/users/mrawls/premap2019/hits-lsst/hits2015/rerun/highres1'\n",
    "butler = dafPersist.Butler(repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbName = 'association.db'\n",
    "dbPath = os.path.join(repo, dbName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the database using sqlite3 and run two queries to make two pandas dataframes. One is all the objects and one is all the sources. Remember objects are composed of one or more sources that have been associated together based on position in the sky.\n",
    "\n",
    "These are big dataframes so they will take a little time to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = sqlite3.connect(dbPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objTable = pd.read_sql_query('select diaObjectId, ra, decl, nDiaSources, \\\n",
    "                              gPSFluxMean, gPSFluxMeanErr, \\\n",
    "                              validityEnd, flags, \\\n",
    "                              gTOTFluxMean, gTOTFluxMeanErr \\\n",
    "                              from DiaObject where validityEnd is NULL;', connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcTableAll = pd.read_sql_query('select diaSourceId, diaObjectId, \\\n",
    "                                  ra, decl, ccdVisitId, \\\n",
    "                                  midPointTai, apFlux, psFlux, apFluxErr, \\\n",
    "                                  psFluxErr, totFlux, totFluxErr, flags \\\n",
    "                                  from DiaSource;', connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objTable.head()\n",
    "# you could also try objTable.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcTableAll.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import a custom function I wrote to handle LSST stuff\n",
    "We'll use `makeSrcTableFlags` to get a version of `srcTableAll` that has \"unpacked\" information about the flags we want to use to filter out some obviously bad sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/epyc/users/mrawls/premap2019/ap_pipe-notebooks/')\n",
    "from apdbPlots import makeSrcTableFlags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've done some work for you already, both in writing these functions and determining that the three flags I put below in `badFlagList` do indeed indicate the source is probably bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "badFlagList = ['base_PixelFlags_flag_bad', 'base_PixelFlags_flag_suspect', 'base_PixelFlags_flag_saturatedCenter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wrote the `makeSrcTableFlags` function to return a **lot** of stuff, so we'll go ahead and give all that stuff variable names, but we probably won't need to use all of it. It might give you a scary looking \"YAMLLoadWarning\" but that's OK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flagTable, flagValues, srcTableFlags, flagFilter, noFlagFilter, \\\n",
    "    goodSrc, goodObj = makeSrcTableFlags(srcTableAll, objTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsstRas = goodObj.ra\n",
    "lsstDecs = goodObj.decl\n",
    "hitsRas = hitsDf.raMedian_feat\n",
    "hitsDecs = hitsDf.decMedian_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so we have RAs and Decs for both catalogs, but how can we tell which object in the LSST catalog corresponds to some given object in the HiTS catalog?\n",
    "Astropy to the rescue!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitsCoords = SkyCoord(ra=hitsRas*u.degree, dec=hitsDecs*u.degree)\n",
    "lsstCoords = SkyCoord(ra=lsstRas*u.degree, dec=lsstDecs*u.degree)\n",
    "idx, d2d, d3d = hitsCoords.match_to_catalog_sky(lsstCoords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we have a powerful function that returns lots of stuff, but we only need the indices (saved in `idx`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx  # these are the indices of lsstCoords corresponding to hitsCoords 0, 1, 2, ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example, this pulls up the row from goodObj that matches hitsDf.iloc[2]\n",
    "goodObj.iloc[idx[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLsstLightcurve(obj, dbPath, fluxCol='totFlux'):\n",
    "    '''Plots a light curve for a DIA (Difference Image Analysis) Object\n",
    "    from an LSST APDB (Alert Production database).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    obj : diaObjectId\n",
    "        a really long integer that lets us retrieve sources for a single object\n",
    "    objTable : Pandas dataframe containing DIA Objects\n",
    "    repo : Butler repository\n",
    "    dbPath : Path on disk to an APDB we can load DIA Objects or DIA Sources from\n",
    "        often the database is named `association.db`\n",
    "    fluxCol : Which flux column to plot?\n",
    "        choices are totFlux, psFlux, apFlux\n",
    "    \n",
    "    '''\n",
    "    plt.figure(figsize=(6,4))\n",
    "    connection = sqlite3.connect(dbPath)\n",
    "    # Load all sources for a single object called \"obj\"\n",
    "    srcTable = pd.read_sql_query(f'select diaSourceId, diaObjectId, \\\n",
    "                                  ra, decl, ccdVisitId, \\\n",
    "                                  midPointTai, apFlux, psFlux, apFluxErr, \\\n",
    "                                  psFluxErr, totFlux, totFluxErr, flags \\\n",
    "                                  from DiaSource where diaObjectId = {obj};', connection)\n",
    "    fluxErrCol = fluxCol + 'Err'\n",
    "    plt.errorbar(srcTable['midPointTai'], srcTable[fluxCol], yerr=srcTable[fluxErrCol],\n",
    "                 ls=':', marker='o')\n",
    "    plt.ylabel(fluxCol + ' (nJy)')\n",
    "    plt.xlabel('Time (MJD)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hits(hitsDf.iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = goodObj.iloc[idx[2]]['diaObjectId']  # can you explain what this line does?\n",
    "plotLsstLightcurve(obj, dbPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose your own adventure\n",
    "* How would you plot both light curves on the same plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: the astropy units module is your friend!\n",
    "lsstTestMag = (140000*u.nJy).to(u.ABmag)\n",
    "print(lsstTestMag.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Is there a particular kind of variable source you are most interested in? The classifications from HiTS DR1 are quasar, CV, RR-Lyrae, eclipsing binary, miscellaneous (lol), supernovae, long-period variable, rotational variable, ZZ Ceti variable, and delta-Scuti variable. Try plotting light curves for those ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: the hitsDf has info about the most likely classificaton!\n",
    "testRow = hitsDf.iloc[2]\n",
    "predicted_class = testRow['Predicted_class'].strip()\n",
    "class_probability = testRow[f\"{predicted_class}_Prob\"]\n",
    "print(f\"{predicted_class} Probability: {class_probability:0.2f}\")\n",
    "print(f\"Variable Probability: {testRow['Variable_prob']:0.2f}\")\n",
    "print(f\"Periodic Probability: {testRow['Periodic_prob']:0.2f}\")\n",
    "print(f\"Variability Amplitude: {testRow['Amplitude']:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in hitsDf.iterrows():\n",
    "    predicted_class = row['Predicted_class'].strip()\n",
    "    class_probability = row[f\"{predicted_class}_Prob\"]\n",
    "    print(idx, f\"{predicted_class} Probability: {class_probability:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Make a new plot of the objects on the sky, using only the no-bad-flag ones (the `goodObj` dataframe). Overplot the HiTS objects and try color-coding them by variability class!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: we made a plot like this in the Nov 13 notebook\n",
    "\n",
    "# Recall in THIS notebook we have already defined lsstRas, lsstDecs,\n",
    "# hitsRas, and hitsDecs\n",
    "\n",
    "def plot_objects_on_sky(ra1_first, dec1_first,\n",
    "                        ra2_first, dec2_first,\n",
    "                        ra1_second, dec1_second,\n",
    "                        ra2_second, dec2_second):\n",
    "    \"\"\"This function takes two sets of RA and Dec and plots them\n",
    "    both on the sky in different colors.\n",
    "    \n",
    "    It is customized to plot a specific region (three HiTS fields in two panels).\n",
    "    \n",
    "    \"1\" and \"2\" refer to the two panels in the plot.\n",
    "    \"first\" and \"second\" refer to the two different datasets.\n",
    "    \"\"\"\n",
    "    # Set up the figure object and two axes\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax1 = plt.subplot2grid((100, 100), (0, 55), rowspan=50, colspan=45)\n",
    "    ax2 = plt.subplot2grid((100, 100), (0, 0), rowspan=90, colspan=50)\n",
    "\n",
    "    # Plot the first set of RAs and Decs in blue\n",
    "    # This will be from the LSST database\n",
    "    ax1.scatter(ra1_first, dec1_first, marker='.', s=0.5, alpha=0.2, c='C0')\n",
    "    ax2.scatter(ra2_first, dec2_first, marker='.', s=0.5, alpha=0.2, c='C0')\n",
    "    \n",
    "    # Plot the second set of RAs and Decs in orange\n",
    "    # This will be from the HiTS DR1\n",
    "    ax1.scatter(ra1_second, dec1_second, marker='.', s=10, alpha=0.8, c='C1')\n",
    "    ax2.scatter(ra2_second, dec2_second, marker='.', s=10, alpha=0.8, c='C1')\n",
    "\n",
    "    ax1.invert_xaxis()\n",
    "    ax2.invert_xaxis()\n",
    "\n",
    "    plt.xlabel('RA (deg)')\n",
    "    plt.ylabel('Dec (deg)')\n",
    "    plt.title('Customized view of objects in the sky')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And this is how we split all the objects into two regions\n",
    "# to make the plot look good\n",
    "\n",
    "ax1Filter_lsst = (goodObj['decl'] > -2)\n",
    "ax2Filter_lsst = (~ax1Filter_lsst)\n",
    "\n",
    "ra1_lsst = goodObj.loc[ax1Filter_lsst, 'ra']\n",
    "dec1_lsst = goodObj.loc[ax1Filter_lsst, 'decl']\n",
    "ra2_lsst = goodObj.loc[ax2Filter_lsst, 'ra']\n",
    "dec2_lsst = goodObj.loc[ax2Filter_lsst, 'decl']\n",
    "\n",
    "ax1Filter_hits = (hitsDf['decMedian'] > -2)\n",
    "ax2Filter_hits = (~ax1Filter_hits)\n",
    "\n",
    "ra1_hits = # finish me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST-mrawls",
   "language": "python",
   "name": "lsst-mrawls"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
